{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b69f581-5078-4729-ac01-803ce93b7153",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91bff465-5819-4e79-9f84-e345232a8bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (23.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "\n",
    "!pip install --upgrade pip\n",
    "%conda install tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d332f7-0b84-481f-a9ef-722bdd47cde9",
   "metadata": {},
   "source": [
    "### Data Import for Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02a6569a-0718-465f-a95c-d85b539b9ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# role = sagemaker.get_execution_role()\n",
    "# region = boto3.Session().region_name\n",
    "\n",
    "# data_bucket = \"dynamodbpetfinder\"\n",
    "# object_prefix = \"interaction_\"\n",
    "# local_path = \"data/interaction/\"\n",
    "\n",
    "# if not os.path.exists(local_path):\n",
    "#     os.makedirs(local_path)\n",
    "# else:\n",
    "#     shutil.rmtree(local_path)\n",
    "#     os.makedirs(local_path)\n",
    "\n",
    "# pattern = r'[0-9]+'\n",
    "# s3 = boto3.client(\"s3\")\n",
    "\n",
    "# result = s3.list_objects(Bucket=data_bucket, Prefix=object_prefix, Delimiter=\"/\")\n",
    "# subfolders = [re.search(pattern, o.get(\"Prefix\")).group() for o in result.get(\"CommonPrefixes\")]\n",
    "# subfolders.sort(reverse=True)\n",
    "\n",
    "# object_path = object_prefix + subfolders[0] + \"/\"\n",
    "# files = s3.list_objects(Bucket=data_bucket, Prefix=object_path, Delimiter=\"/\")\n",
    "\n",
    "# pattern = rf'{object_path}(.+)'\n",
    "# for content in files.get(\"Contents\"):\n",
    "#     file_path = content.get(\"Key\")\n",
    "#     filename = re.findall(pattern, file_path)[0]\n",
    "#     print(filename)\n",
    "\n",
    "#     with open(local_path+filename, 'wb') as file:\n",
    "#         s3.download_fileobj(\n",
    "#             Bucket=data_bucket,\n",
    "#             Key=file_path,\n",
    "#             Fileobj=file\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee5827a9-5d76-48e4-b966-b866b7d2beaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_list = glob.glob(local_path + \"*\")\n",
    "\n",
    "# print(file_list)\n",
    "\n",
    "# dfs = [] # an empty list to store the data frames\n",
    "# for file in file_list:\n",
    "#     data = pd.read_csv(file) # read data frame from csv file\n",
    "#     dfs.append(data) # append the data frame to the list\n",
    "    \n",
    "# interactions = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773fe0e-a1b4-4b4e-8325-2e6d29fc2cee",
   "metadata": {},
   "source": [
    "## Data Import for Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a6463f9-68e9-4fb5-8413-26a69d7d188c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-1686726820579-part-r-00000\n",
      "run-1686726820579-part-r-00001\n",
      "run-1686726820579-part-r-00002\n",
      "run-1686726820579-part-r-00003\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "data_bucket = \"dynamodbpetfinder\"\n",
    "object_prefix = \"cat_\"\n",
    "local_path = \"data/cat/\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "else:\n",
    "    shutil.rmtree(local_path)\n",
    "    os.makedirs(local_path)\n",
    "\n",
    "pattern = r'[0-9]+'\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "result = s3.list_objects(Bucket=data_bucket, Prefix=object_prefix, Delimiter=\"/\")\n",
    "subfolders = [re.search(pattern, o.get(\"Prefix\")).group() for o in result.get(\"CommonPrefixes\")]\n",
    "subfolders.sort(reverse=True)\n",
    "\n",
    "object_path = object_prefix + subfolders[0] + \"/\"\n",
    "files = s3.list_objects(Bucket=data_bucket, Prefix=object_path, Delimiter=\"/\")\n",
    "\n",
    "pattern = rf'{object_path}(.+)'\n",
    "for content in files.get(\"Contents\"):\n",
    "    file_path = content.get(\"Key\")\n",
    "    filename = re.findall(pattern, file_path)[0]\n",
    "    print(filename)\n",
    "\n",
    "    with open(local_path+filename, 'wb') as file:\n",
    "        s3.download_fileobj(\n",
    "            Bucket=data_bucket,\n",
    "            Key=file_path,\n",
    "            Fileobj=file\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a95d513f-2753-40a8-a477-81b9740584dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/cat/run-1686726820579-part-r-00003', 'data/cat/run-1686726820579-part-r-00001', 'data/cat/run-1686726820579-part-r-00000', 'data/cat/run-1686726820579-part-r-00002']\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(local_path + \"*\")\n",
    "\n",
    "print(file_list)\n",
    "\n",
    "dfs = [] # an empty list to store the data frames\n",
    "for file in file_list:\n",
    "    data = pd.read_csv(file) # read data frame from csv file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "    \n",
    "cats = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6c03939-3e56-4f38-904b-2a424fb8be2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cws_id</th>\n",
       "      <th>C_othercats</th>\n",
       "      <th>C_kids</th>\n",
       "      <th>C_primarycolor</th>\n",
       "      <th>name</th>\n",
       "      <th>C_employment</th>\n",
       "      <th>sweet</th>\n",
       "      <th>C_homeownership</th>\n",
       "      <th>active</th>\n",
       "      <th>...</th>\n",
       "      <th>quiet</th>\n",
       "      <th>C_otherdogs</th>\n",
       "      <th>C_attention</th>\n",
       "      <th>loving</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>C_adoptionfee</th>\n",
       "      <th>C_sweetspicy</th>\n",
       "      <th>description</th>\n",
       "      <th>spicy</th>\n",
       "      <th>C_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54b908dd-a325-459a-bdcb-5b1901d8324e</td>\n",
       "      <td>1681491254-120</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>BoyBoy the oriental mix tabby cat</td>\n",
       "      <td>no preference</td>\n",
       "      <td>True</td>\n",
       "      <td>owned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>independent</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-05-15T02:51:11.735Z</td>\n",
       "      <td>yes</td>\n",
       "      <td>sweet</td>\n",
       "      <td>quiet, loving, sweet, shy</td>\n",
       "      <td>False</td>\n",
       "      <td>chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a929522-33b0-42f2-8a80-a6f097a0e1fe</td>\n",
       "      <td>1681491547-251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Mike and Bella</td>\n",
       "      <td>working full time</td>\n",
       "      <td>True</td>\n",
       "      <td>no preference</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-05-15T02:51:14.961Z</td>\n",
       "      <td>no preference</td>\n",
       "      <td>sweet</td>\n",
       "      <td>playful, active, loving, sweet</td>\n",
       "      <td>False</td>\n",
       "      <td>high energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3538eec-3e8b-4c48-9adf-08c5c5fbbfce</td>\n",
       "      <td>1681491592-271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Maya for adoption</td>\n",
       "      <td>student</td>\n",
       "      <td>False</td>\n",
       "      <td>parents</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-05-15T02:51:19.367Z</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b79b5e65-621b-4906-aea4-fffef2259fec</td>\n",
       "      <td>1681491440-203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Calico/Tortie</td>\n",
       "      <td>Sally – 8 mths old tortoiseshell</td>\n",
       "      <td>working full time</td>\n",
       "      <td>False</td>\n",
       "      <td>owned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>independent</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-05-15T02:51:36.655Z</td>\n",
       "      <td>no preference</td>\n",
       "      <td>sweet</td>\n",
       "      <td>quiet, loving, friendly</td>\n",
       "      <td>False</td>\n",
       "      <td>chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6117e9df-fa0f-43dd-b6cb-b62a8748bfd8</td>\n",
       "      <td>1681491915-414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Matcha</td>\n",
       "      <td>working full time</td>\n",
       "      <td>True</td>\n",
       "      <td>owned</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-05-15T02:51:50.223Z</td>\n",
       "      <td>yes</td>\n",
       "      <td>sweet</td>\n",
       "      <td>loving, sweet</td>\n",
       "      <td>False</td>\n",
       "      <td>chill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id          cws_id  C_othercats  C_kids  \\\n",
       "0  54b908dd-a325-459a-bdcb-5b1901d8324e  1681491254-120           -1       0   \n",
       "1  1a929522-33b0-42f2-8a80-a6f097a0e1fe  1681491547-251            1       0   \n",
       "2  b3538eec-3e8b-4c48-9adf-08c5c5fbbfce  1681491592-271            0       0   \n",
       "3  b79b5e65-621b-4906-aea4-fffef2259fec  1681491440-203            1       0   \n",
       "4  6117e9df-fa0f-43dd-b6cb-b62a8748bfd8  1681491915-414            0       0   \n",
       "\n",
       "  C_primarycolor                               name       C_employment  sweet  \\\n",
       "0          White  BoyBoy the oriental mix tabby cat      no preference   True   \n",
       "1          Tabby                     Mike and Bella  working full time   True   \n",
       "2          White                  Maya for adoption            student  False   \n",
       "3  Calico/Tortie   Sally – 8 mths old tortoiseshell  working full time  False   \n",
       "4          Tabby                             Matcha  working full time   True   \n",
       "\n",
       "  C_homeownership  active  ...  quiet  C_otherdogs  C_attention loving  \\\n",
       "0           owned   False  ...   True            0  independent   True   \n",
       "1   no preference    True  ...  False            0          NaN   True   \n",
       "2         parents   False  ...  False            0          NaN  False   \n",
       "3           owned   False  ...   True            0  independent   True   \n",
       "4           owned   False  ...  False            0          NaN   True   \n",
       "\n",
       "                  updatedAt  C_adoptionfee  C_sweetspicy  \\\n",
       "0  2023-05-15T02:51:11.735Z            yes         sweet   \n",
       "1  2023-05-15T02:51:14.961Z  no preference         sweet   \n",
       "2  2023-05-15T02:51:19.367Z            yes           NaN   \n",
       "3  2023-05-15T02:51:36.655Z  no preference         sweet   \n",
       "4  2023-05-15T02:51:50.223Z            yes         sweet   \n",
       "\n",
       "                      description  spicy     C_energy  \n",
       "0       quiet, loving, sweet, shy  False        chill  \n",
       "1  playful, active, loving, sweet  False  high energy  \n",
       "2                             NaN  False        chill  \n",
       "3         quiet, loving, friendly  False        chill  \n",
       "4                   loving, sweet  False        chill  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda687bf-9031-4578-b1ff-929c6494e137",
   "metadata": {},
   "source": [
    "### Data Import for Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74e10308-bb6a-4764-bbc3-9f9bfc5fe331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-1686726799591-part-r-00000\n",
      "run-1686726799591-part-r-00001\n",
      "run-1686726799591-part-r-00002\n",
      "run-1686726799591-part-r-00003\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "data_bucket = \"dynamodbpetfinder\"\n",
    "object_prefix = \"user_\"\n",
    "local_path = \"data/user/\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "else:\n",
    "    shutil.rmtree(local_path)\n",
    "    os.makedirs(local_path)\n",
    "\n",
    "pattern = r'[0-9]+'\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "result = s3.list_objects(Bucket=data_bucket, Prefix=object_prefix, Delimiter=\"/\")\n",
    "subfolders = [re.search(pattern, o.get(\"Prefix\")).group() for o in result.get(\"CommonPrefixes\")]\n",
    "subfolders.sort(reverse=True)\n",
    "\n",
    "object_path = object_prefix + subfolders[0] + \"/\"\n",
    "files = s3.list_objects(Bucket=data_bucket, Prefix=object_path, Delimiter=\"/\")\n",
    "\n",
    "pattern = rf'{object_path}(.+)'\n",
    "for content in files.get(\"Contents\"):\n",
    "    file_path = content.get(\"Key\")\n",
    "    filename = re.findall(pattern, file_path)[0]\n",
    "    print(filename)\n",
    "\n",
    "    with open(local_path+filename, 'wb') as file:\n",
    "        s3.download_fileobj(\n",
    "            Bucket=data_bucket,\n",
    "            Key=file_path,\n",
    "            Fileobj=file\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db46080e-e10e-41d3-bada-6f596d220c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/user/run-1686726799591-part-r-00002', 'data/user/run-1686726799591-part-r-00000', 'data/user/run-1686726799591-part-r-00003', 'data/user/run-1686726799591-part-r-00001']\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(local_path + \"*\")\n",
    "\n",
    "print(file_list)\n",
    "\n",
    "dfs = [] # an empty list to store the data frames\n",
    "for file in file_list:\n",
    "    data = pd.read_json(file, lines=True) # read data frame from json file\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "    \n",
    "users = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f595b87d-1ee1-4868-baed-92fb4c5c097a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>__typename</th>\n",
       "      <th>A_othercats</th>\n",
       "      <th>A_sweetspicy</th>\n",
       "      <th>_lastChangedAt</th>\n",
       "      <th>A_agegroup</th>\n",
       "      <th>A_gender</th>\n",
       "      <th>A_otherdogs</th>\n",
       "      <th>A_employment</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>...</th>\n",
       "      <th>A_firstcat</th>\n",
       "      <th>A_kids</th>\n",
       "      <th>_version</th>\n",
       "      <th>A_attention</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>A_primarycolor</th>\n",
       "      <th>username</th>\n",
       "      <th>A_homeownership</th>\n",
       "      <th>A_allergies</th>\n",
       "      <th>A_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2fe504c-8b80-4f50-ab07-12b6e7ff8cd2</td>\n",
       "      <td>User</td>\n",
       "      <td>-1</td>\n",
       "      <td>Anything is nice</td>\n",
       "      <td>1686310110279</td>\n",
       "      <td>[{'S': 'Kitten'}, {'S': 'Juvenile'}]</td>\n",
       "      <td>No preference</td>\n",
       "      <td>-1</td>\n",
       "      <td>Student</td>\n",
       "      <td>2023-06-09T11:28:30.250Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>2023-06-09T11:28:30.250Z</td>\n",
       "      <td>[{'S': 'No preference'}]</td>\n",
       "      <td>gadmantang</td>\n",
       "      <td>Staying with Parents</td>\n",
       "      <td>-1</td>\n",
       "      <td>Chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>079b0ec9-cec6-42fb-9f00-7891c52a10fb</td>\n",
       "      <td>User</td>\n",
       "      <td>-1</td>\n",
       "      <td>All sweet</td>\n",
       "      <td>1684430025291</td>\n",
       "      <td>[{'S': 'Juvenile'}]</td>\n",
       "      <td>No preference</td>\n",
       "      <td>-1</td>\n",
       "      <td>Working Full Time</td>\n",
       "      <td>2023-05-18T17:13:45.262Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>No preference</td>\n",
       "      <td>2023-05-18T17:13:45.262Z</td>\n",
       "      <td>[{'S': 'No preference'}]</td>\n",
       "      <td>Goodboya</td>\n",
       "      <td>Self-Owned</td>\n",
       "      <td>-1</td>\n",
       "      <td>No preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6abb6324-ae5e-48d5-a55f-0134f21c79c2</td>\n",
       "      <td>User</td>\n",
       "      <td>-1</td>\n",
       "      <td>Some spice</td>\n",
       "      <td>1684409930581</td>\n",
       "      <td>[{'S': 'No preference'}, {'S': 'Kitten'}, {'S'...</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>Student</td>\n",
       "      <td>2023-05-18T11:38:50.554Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>2023-05-18T11:38:50.554Z</td>\n",
       "      <td>[{'S': 'No preference'}]</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>Staying with Parents</td>\n",
       "      <td>-1</td>\n",
       "      <td>Chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fab5c53d-493a-4baf-b8e5-3cd1e505d75e</td>\n",
       "      <td>User</td>\n",
       "      <td>-1</td>\n",
       "      <td>All sweet</td>\n",
       "      <td>1685623771616</td>\n",
       "      <td>[{'S': 'No preference'}, {'S': 'Kitten'}]</td>\n",
       "      <td>No preference</td>\n",
       "      <td>-1</td>\n",
       "      <td>Working Full Time</td>\n",
       "      <td>2023-06-01T12:49:31.590Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>An attention seeker</td>\n",
       "      <td>2023-06-01T12:49:31.590Z</td>\n",
       "      <td>[{'S': 'No preference'}, {'S': 'Calico/Tortie'}]</td>\n",
       "      <td>Testing :)</td>\n",
       "      <td>Self-Owned</td>\n",
       "      <td>-1</td>\n",
       "      <td>No preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6c66277d-fc3b-4d17-9c90-f1f37579109a</td>\n",
       "      <td>User</td>\n",
       "      <td>-1</td>\n",
       "      <td>All sweet</td>\n",
       "      <td>1684431886401</td>\n",
       "      <td>[{'S': 'Kitten'}]</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Student</td>\n",
       "      <td>2023-05-18T17:44:46.373Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Independent</td>\n",
       "      <td>2023-05-18T17:44:46.373Z</td>\n",
       "      <td>[{'S': 'No preference'}]</td>\n",
       "      <td>ridhicar</td>\n",
       "      <td>Staying with Parents</td>\n",
       "      <td>-1</td>\n",
       "      <td>High energy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id __typename  A_othercats  \\\n",
       "0  b2fe504c-8b80-4f50-ab07-12b6e7ff8cd2       User           -1   \n",
       "1  079b0ec9-cec6-42fb-9f00-7891c52a10fb       User           -1   \n",
       "2  6abb6324-ae5e-48d5-a55f-0134f21c79c2       User           -1   \n",
       "3  fab5c53d-493a-4baf-b8e5-3cd1e505d75e       User           -1   \n",
       "4  6c66277d-fc3b-4d17-9c90-f1f37579109a       User           -1   \n",
       "\n",
       "       A_sweetspicy  _lastChangedAt  \\\n",
       "0  Anything is nice   1686310110279   \n",
       "1         All sweet   1684430025291   \n",
       "2        Some spice   1684409930581   \n",
       "3         All sweet   1685623771616   \n",
       "4         All sweet   1684431886401   \n",
       "\n",
       "                                          A_agegroup       A_gender  \\\n",
       "0               [{'S': 'Kitten'}, {'S': 'Juvenile'}]  No preference   \n",
       "1                                [{'S': 'Juvenile'}]  No preference   \n",
       "2  [{'S': 'No preference'}, {'S': 'Kitten'}, {'S'...           Male   \n",
       "3          [{'S': 'No preference'}, {'S': 'Kitten'}]  No preference   \n",
       "4                                  [{'S': 'Kitten'}]         Female   \n",
       "\n",
       "   A_otherdogs       A_employment                 createdAt  ...  A_firstcat  \\\n",
       "0           -1            Student  2023-06-09T11:28:30.250Z  ...           1   \n",
       "1           -1  Working Full Time  2023-05-18T17:13:45.262Z  ...           1   \n",
       "2           -1            Student  2023-05-18T11:38:50.554Z  ...           1   \n",
       "3           -1  Working Full Time  2023-06-01T12:49:31.590Z  ...           1   \n",
       "4            1            Student  2023-05-18T17:44:46.373Z  ...           1   \n",
       "\n",
       "   A_kids  _version          A_attention                 updatedAt  \\\n",
       "0      -1         1          Independent  2023-06-09T11:28:30.250Z   \n",
       "1      -1         1        No preference  2023-05-18T17:13:45.262Z   \n",
       "2      -1         1          Independent  2023-05-18T11:38:50.554Z   \n",
       "3      -1         1  An attention seeker  2023-06-01T12:49:31.590Z   \n",
       "4       1         1          Independent  2023-05-18T17:44:46.373Z   \n",
       "\n",
       "                                     A_primarycolor    username  \\\n",
       "0                          [{'S': 'No preference'}]  gadmantang   \n",
       "1                          [{'S': 'No preference'}]    Goodboya   \n",
       "2                          [{'S': 'No preference'}]    John Doe   \n",
       "3  [{'S': 'No preference'}, {'S': 'Calico/Tortie'}]  Testing :)   \n",
       "4                          [{'S': 'No preference'}]    ridhicar   \n",
       "\n",
       "        A_homeownership A_allergies       A_energy  \n",
       "0  Staying with Parents          -1          Chill  \n",
       "1            Self-Owned          -1  No preference  \n",
       "2  Staying with Parents          -1          Chill  \n",
       "3            Self-Owned          -1  No preference  \n",
       "4  Staying with Parents          -1    High energy  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c90af0-7916-4598-a3d4-7f5c43910543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "571e66a5-8f44-4a4a-a7d8-d7d5fbe87bab",
   "metadata": {},
   "source": [
    "## Define a Processing Step for Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ab11e-fcdf-404a-b3e4-a3d5ca5db528",
   "metadata": {},
   "source": [
    "### Preprocessing for Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d718d28f-3323-4110-99d1-4c181a92b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename headers\n",
    "cl_users = users.rename(columns={'A_gender': 'gender',\n",
    "                              'A_primarycolor': 'primary_color',\n",
    "                              'A_agegroup': 'age_group',\n",
    "                              'A_energy': 'energy_level',\n",
    "                              'A_attention': 'attention_need',\n",
    "                              'A_sweetspicy': 'personality',\n",
    "                              'A_firstcat': 'is_first_cat',\n",
    "                              'A_othercats': 'has_other_cats',\n",
    "                              'A_otherdogs': 'good_with_other_dogs',\n",
    "                              'A_kids': 'good_with_kids',\n",
    "                              'A_employment': 'employment',\n",
    "                              'A_homeownership': 'home_ownership',\n",
    "                              'A_allergies': 'has_allergies',\n",
    "                              'A_adoptionfee': 'agree_to_fee',\n",
    "                              'createdAt': 'created_at',\n",
    "                              'updatedAt': 'updated_at',\n",
    "                              })\n",
    "\n",
    "# clean multi-select columns with No Preference options (age, color)\n",
    "\n",
    "def clean_multi_select(row):\n",
    "    arr = [o.get(\"S\") for o in row]\n",
    "    if (len(arr) > 1) and ('No preference' in arr):\n",
    "        arr.remove('No preference')\n",
    "    return [s.lower() for s in arr]\n",
    "\n",
    "cl_users['age_group'] = cl_users['age_group'].map(lambda choice: clean_multi_select(choice))\n",
    "cl_users['primary_color'] = cl_users['primary_color'].map(lambda choice: clean_multi_select(choice))\n",
    "\n",
    "\n",
    "# split columns with list (age, color)\n",
    "age_groups = cl_users['age_group'].explode().unique().tolist()\n",
    "split_age_groups = cl_users['age_group'].map(lambda row: ','.join([str(age in row) for age in age_groups]))\n",
    "new_age_columns = split_age_groups.str.split(',', expand=True)\n",
    "new_age_columns = new_age_columns.applymap(lambda val: (val == 'True'))\n",
    "# new_age_columns = new_age_columns.astype('bool')\n",
    "new_age_columns = new_age_columns.astype('int')\n",
    "\n",
    "pattern = re.compile(r'\\s|/')\n",
    "# new_age_columns.columns = [f'age_{pattern.sub(\"_\", age).lower()}' for age in age_groups]\n",
    "cl_users[[f'age_{pattern.sub(\"_\", age).lower()}' for age in age_groups]] = new_age_columns\n",
    "cl_users = cl_users.drop('age_group', axis=1)\n",
    "\n",
    "color_groups = cl_users['primary_color'].explode().unique().tolist()\n",
    "split_color_groups = cl_users['primary_color'].map(lambda row: ','.join([str(color in row) for color in color_groups]))\n",
    "new_color_columns = split_color_groups.str.split(',', expand=True)\n",
    "new_color_columns = new_color_columns.applymap(lambda val: (val == 'True'))\n",
    "# new_color_columns = new_color_columns.astype('bool')\n",
    "new_color_columns = new_color_columns.astype('int')\n",
    "\n",
    "cl_users[[f'primary_color_{pattern.sub(\"_\", color).lower()}' for color in color_groups]] = new_color_columns\n",
    "cl_users = cl_users.drop('primary_color', axis=1)\n",
    "\n",
    "\n",
    "# convert string fields to lower case (gender, energy_level, attention_need, personality, employment, home_ownership)\n",
    "cl_users['gender'] = cl_users['gender'].map(lambda val: val.lower())\n",
    "cl_users['energy_level'] = cl_users['energy_level'].map(lambda val: val.lower())\n",
    "cl_users['attention_need'] = cl_users['attention_need'].map(lambda val: val.lower())\n",
    "cl_users['personality'] = cl_users['personality'].map(lambda val: val.lower())\n",
    "cl_users['employment'] = cl_users['employment'].map(lambda val: val.lower())\n",
    "cl_users['home_ownership'] = cl_users['home_ownership'].map(lambda val: val.lower())\n",
    "\n",
    "\n",
    "\n",
    "# # convert int booleans to actual booleans (is_first_cat, has_other_cats, good_with_other_dogs, good_with_kids, has_allergies, agree_to_fee)\n",
    "cl_users['is_first_cat'] = cl_users['is_first_cat'].map(lambda val: (val == 1))\n",
    "cl_users['has_other_cats'] = cl_users['has_other_cats'].map(lambda val: (val == 1))\n",
    "cl_users['good_with_other_dogs'] = cl_users['good_with_other_dogs'].map(lambda val: (val == 1))\n",
    "cl_users['good_with_kids'] = cl_users['good_with_kids'].map(lambda val: (val == 1))\n",
    "cl_users['has_allergies'] = cl_users['has_allergies'].map(lambda val: (val == 1))\n",
    "cl_users['agree_to_fee'] = cl_users['agree_to_fee'].map(lambda val: (val == 1))\n",
    "\n",
    "# convert types\n",
    "cl_users['created_at'] = pd.to_datetime(cl_users['created_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "cl_users['updated_at'] = pd.to_datetime(cl_users['updated_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "cl_users = cl_users.astype({\n",
    "                          'is_first_cat': 'int',\n",
    "                          'has_other_cats': 'int',\n",
    "                          'good_with_other_dogs': 'int',\n",
    "                          'good_with_kids': 'int',\n",
    "                          'has_allergies': 'int',\n",
    "                          'agree_to_fee': 'int',\n",
    "                          'created_at': 'object',\n",
    "                          'updated_at': 'object',\n",
    "                          })\n",
    "\n",
    "# drop glue columns\n",
    "cl_users = cl_users.drop(['__typename', '_lastChangedAt', '_version'], axis=1)\n",
    "\n",
    "cl_users = cl_users.set_index('id')\n",
    "\n",
    "## Export Processed Data as csv to Local Folder\n",
    "processed_folder = \"processed/auxiliary/\"\n",
    "\n",
    "if not os.path.exists(processed_folder):\n",
    "    os.makedirs(processed_folder)\n",
    "\n",
    "cl_users.to_csv(f'{processed_folder}users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7ccb1-61dc-4bdb-8f24-66f51b828361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea4a211f-7038-4168-a2ed-334c153a2733",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing for Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82ea5fba-8649-4409-bfb0-05e6ea3dbc3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.7/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from opencv-python-headless) (1.18.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install tensorflow\n",
    "%pip install -U opencv-python-headless\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# rename headers\n",
    "cl_cats = cats.rename(columns={'C_gender': 'gender',\n",
    "                              'C_primarycolor': 'primary_color',\n",
    "                              'C_agegroup': 'age_group',\n",
    "                              'C_energy': 'energy_level',\n",
    "                              'C_attention': 'attention_need',\n",
    "                              'C_sweetspicy': 'personality',\n",
    "                              'C_firstcat': 'good_first_cat',\n",
    "                              'C_othercats': 'good_with_other_cats',\n",
    "                              'C_otherdogs': 'good_with_other_dogs',\n",
    "                              'C_kids': 'good_with_kids',\n",
    "                              'C_employment': 'preferred_employment',\n",
    "                              'C_homeownership': 'preferred_home_ownership',\n",
    "                              'C_allergies': 'good_with_allergies',\n",
    "                              'C_adoptionfee': 'require_fee',\n",
    "                              'createdAt': 'created_at',\n",
    "                              'updatedAt': 'updated_at',\n",
    "                              })\n",
    "\n",
    "\n",
    "# fill attention and personality columns as neutral\n",
    "cl_cats['attention_need'] = cl_cats['attention_need'].fillna('neutral')\n",
    "cl_cats['personality'] = cl_cats['personality'].fillna('neutral')\n",
    "\n",
    "# fill empty description with no description available\n",
    "cl_cats['description'] = cl_cats['description'].fillna('no description available')\n",
    "\n",
    "\n",
    "\n",
    "# map integers in categorical columns\n",
    "def map_categorical(val):\n",
    "    if val == 1:\n",
    "        return 'yes'\n",
    "    elif val == -1:\n",
    "        return 'no'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "cl_cats['good_first_cat'] = cl_cats['good_first_cat'].map(lambda val: map_categorical(val))\n",
    "cl_cats['good_with_other_cats'] = cl_cats['good_with_other_cats'].map(lambda val: map_categorical(val))\n",
    "cl_cats['good_with_other_dogs'] = cl_cats['good_with_other_dogs'].map(lambda val: map_categorical(val))\n",
    "cl_cats['good_with_kids'] = cl_cats['good_with_kids'].map(lambda val: map_categorical(val))\n",
    "\n",
    "# convert string fields to lower case (gender, breed, primary_color, age_group, energy_level, attention_need, personality, preferred_employment, preferred_home_ownership, require_fee)\n",
    "cl_cats['gender'] = cl_cats['gender'].map(lambda val: val.lower())\n",
    "cl_cats['breed'] = cl_cats['breed'].map(lambda val: val.lower())\n",
    "cl_cats['primary_color'] = cl_cats['primary_color'].map(lambda val: val.lower())\n",
    "cl_cats['age_group'] = cl_cats['age_group'].map(lambda val: val.lower())\n",
    "cl_cats['energy_level'] = cl_cats['energy_level'].map(lambda val: val.lower())\n",
    "cl_cats['attention_need'] = cl_cats['attention_need'].map(lambda val: val.lower())\n",
    "cl_cats['personality'] = cl_cats['personality'].map(lambda val: val.lower())\n",
    "cl_cats['preferred_employment'] = cl_cats['preferred_employment'].map(lambda val: val.lower())\n",
    "cl_cats['preferred_home_ownership'] = cl_cats['preferred_home_ownership'].map(lambda val: val.lower())\n",
    "cl_cats['require_fee'] = cl_cats['require_fee'].map(lambda val: val.lower())\n",
    "\n",
    "cl_cats['description'] = cl_cats['description'].map(lambda val: val.encode(\"ascii\", \"ignore\").decode().replace('\\n', ' ').replace('\\r', '').lower())\n",
    "cl_cats['details'] = cl_cats['details'].map(lambda val: val.encode(\"ascii\", \"ignore\").decode().replace('\\n', ' ').replace('\\r', '').lower())\n",
    "\n",
    "# convert types\n",
    "cl_cats['created_at'] = pd.to_datetime(cl_cats['created_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "cl_cats['updated_at'] = pd.to_datetime(cl_cats['updated_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "cl_cats = cl_cats.astype({'playful': 'int',\n",
    "                          'active': 'int',\n",
    "                          'curious': 'int',\n",
    "                          'talkative': 'int',\n",
    "                          'quiet': 'int',\n",
    "                          'loving': 'int',\n",
    "                          'sweet': 'int',\n",
    "                          'likes_held': 'int',\n",
    "                          'friendly': 'int',\n",
    "                          'shy': 'int',\n",
    "                          'spicy': 'int',\n",
    "                          'loves_attention': 'int'\n",
    "                          })\n",
    "\n",
    "# drop glue columns\n",
    "cl_cats = cl_cats.drop(['__typename', '_lastChangedAt', '_version'], axis=1)\n",
    "\n",
    "## Export Processed Data as csv to Local Folder\n",
    "processed_folder = \"processed/auxiliary/\"\n",
    "\n",
    "if not os.path.exists(processed_folder):\n",
    "    os.makedirs(processed_folder)\n",
    "\n",
    "cl_cats.to_csv(f'{processed_folder}cats.csv')\n",
    "\n",
    "## cat profile images\n",
    "\n",
    "new_size = 128\n",
    "\n",
    "data_bucket = \"petfinder6000images\"\n",
    "local_path = \"data/cat_images/\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.makedirs(local_path)\n",
    "else:\n",
    "    shutil.rmtree(local_path)\n",
    "    os.makedirs(local_path)\n",
    "    \n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "\n",
    "def vectorise(cws_id):\n",
    "    filename = f'cropped_{cws_id}.jpg'\n",
    "    s3.download_file(\n",
    "        Bucket=data_bucket,\n",
    "        Key=filename,\n",
    "        Filename=local_path+filename\n",
    "    )\n",
    "    \n",
    "    img = cv2.imread(local_path+filename)\n",
    "    try:\n",
    "        resize = cv2.resize(img, (new_size, new_size))\n",
    "        resize = cv2.cvtColor(resize,cv2.COLOR_BGR2RGB)\n",
    "        resize = np.array(resize.tolist())/255.0\n",
    "        return resize\n",
    "        # img_flat = resize.reshape(-1)\n",
    "        # return str(np.array2string(img_flat, precision=2, separator=',', suppress_small=True)).encode('utf-8')\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "cat_images = cl_cats.loc[:, ['cws_id', 'updated_at']]\n",
    "cat_images['img_shape'] = str([new_size, new_size, 3])\n",
    "cat_images['img_vector'] = cat_images['cws_id'].map(lambda cws_id: vectorise(cws_id))\n",
    "\n",
    "img_vectors = cat_images['img_vector'].values\n",
    "\n",
    "\n",
    "\n",
    "# Using a pretrained model to generate features\n",
    "\n",
    "#### Importing pretrained MobileNetV2\n",
    "mnetv2_base = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(new_size,new_size,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freezing layers\n",
    "for layer in mnetv2_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "# defining a function to extract features\n",
    "def img_feature_extraction(img_vectors, pre_model):\n",
    "\n",
    "    batch_img = []\n",
    "    \n",
    "    # preprocessing and then using pretrained model to extract features\n",
    "    for image in img_vectors:\n",
    "        im_toarray = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        \n",
    "        im_toarray = np.expand_dims(image, axis=0)\n",
    "        im_toarray = tf.keras.applications.mobilenet.preprocess_input(im_toarray)\n",
    "        \n",
    "        batch_img.append(im_toarray)\n",
    "        \n",
    "    batch_img = np.vstack(batch_img)\n",
    "    features = pre_model.predict(batch_img, batch_size=64)\n",
    "    features= features.reshape((len(img_vectors), -1))\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "# Extract features\n",
    "features = img_feature_extraction(img_vectors, mnetv2_base)\n",
    "\n",
    "features.shape\n",
    "\n",
    "# add the feature vectors to dataframe\n",
    "feature_vectors = pd.Series(features.tolist(), index = cat_images.index)\n",
    "cat_images = cat_images.merge(feature_vectors.rename('feature_vectors'), left_index=True, right_index=True)\n",
    "\n",
    "# stringify vectors\n",
    "\n",
    "cat_images['feature_vectors']=cat_images['feature_vectors'].astype(pd.StringDtype())\n",
    "\n",
    "cat_images['img_vector']=cat_images['img_vector'].apply(lambda x: x.reshape(-1))\n",
    "cat_images['img_vector']=cat_images['img_vector'].astype(pd.StringDtype())\n",
    "\n",
    "\n",
    "\n",
    "def cast_object_to_string(data_frame):\n",
    "    \"\"\"\n",
    "    Cast all columns of data_frame of type object to type string and return it.\n",
    "    Parameters:\n",
    "        data_frame: A pandas Dataframe\n",
    "    Returns:\n",
    "        Data frame\n",
    "    \"\"\"\n",
    "    for label in data_frame.columns:\n",
    "        if data_frame.dtypes[label] == object:\n",
    "            data_frame[label] = data_frame[label].astype(\"str\").astype(\"string\")\n",
    "    return data_frame\n",
    "\n",
    "cat_images = cast_object_to_string(cat_images)\n",
    "\n",
    "cat_images = cat_images.reset_index()\n",
    "\n",
    "\n",
    "processed_folder = \"processed/auxiliary/\"\n",
    "\n",
    "if not os.path.exists(processed_folder):\n",
    "    os.makedirs(processed_folder)\n",
    "\n",
    "cat_images.to_pickle(f'{processed_folder}cat-images.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c856b06-5ea0-4f23-82ba-7a597b93ca81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c4c2c37-0470-48f6-af2b-181ef5bb68d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#     # rename headers\n",
    "#     cl_interactions = interactions.rename(columns={\n",
    "#                                   'createdAt': 'created_at',\n",
    "#                                   'updatedAt': 'updated_at',\n",
    "#                                   })\n",
    "\n",
    "#     # convert types\n",
    "#     cl_interactions = cl_interactions.astype({\n",
    "#                               'like': 'int',\n",
    "#                               'click': 'int',\n",
    "#                               })\n",
    "#     cl_interactions['created_at'] = pd.to_datetime(cl_interactions['created_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "#     cl_interactions['updated_at'] = pd.to_datetime(cl_interactions['updated_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "#     # drop glue columns\n",
    "#     cl_interactions = cl_interactions.drop(['__typename', '_lastChangedAt', '_version'], axis=1)\n",
    "\n",
    "#     # exporting processed data as csv to local folder\n",
    "\n",
    "#     processed_folder = \"processed/auxiliary/\"\n",
    "\n",
    "#     if not os.path.exists(processed_folder):\n",
    "#         os.makedirs(processed_folder)\n",
    "\n",
    "#     cl_interactions.to_csv(f'{processed_folder}interactions.csv')\n",
    "  \n",
    "#     ## train-test split \n",
    "\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "\n",
    "#     test_size = 0.2\n",
    "#     validation_size = 0.5 # of test size\n",
    "#     random_state = 2023\n",
    "\n",
    "#     ## leave some users out\n",
    "#     data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "#     os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "#     output_dir = os.path.join(os.getcwd(), \"data/output\")\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     users = cl_interactions['userID'].unique()\n",
    "    \n",
    "#     train_users, test_users = train_test_split(users, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "#     validation_users, test_users = train_test_split(test_users, test_size=validation_size, shuffle=True, random_state=random_state)\n",
    "\n",
    "#     train_set = cl_interactions[cl_interactions['userID'].isin(train_users)]\n",
    "#     validation_set = cl_interactions[cl_interactions['userID'].isin(validation_users)]\n",
    "#     test_set = cl_interactions[cl_interactions['userID'].isin(test_users)]\n",
    "#     print(train_set)\n",
    "#     train_set.to_csv('../data/output/lsuo_train.csv')\n",
    "#     validation_set.to_csv('../data/output/lsuo_validation.csv')\n",
    "#     test_set.to_csv('../data/output/lsuo_test.csv')\n",
    "\n",
    "#     ## stratified split\n",
    "\n",
    "#     train_set = cl_interactions.groupby('userID').sample(frac=1-test_size, random_state=random_state)\n",
    "#     test_set = cl_interactions.drop(train_set.index)\n",
    "\n",
    "#     validation_set = test_set.groupby('userID').sample(frac=validation_size, random_state=random_state)\n",
    "#     test_set = test_set.drop(validation_set.index)\n",
    "\n",
    "#     print(f'Total number of users: {cl_interactions[\"userID\"].nunique()}')\n",
    "#     print(f'Number of users in training: {train_set[\"userID\"].nunique()}')\n",
    "#     print(f'Number of users in validation: {validation_set[\"userID\"].nunique()}')\n",
    "#     print(f'Number of users in test: {test_set[\"userID\"].nunique()}')\n",
    "\n",
    "#     train_set.to_csv('../data/output/strat_train.csv')\n",
    "#     validation_set.to_csv('../data/output/strat_validation.csv')\n",
    "#     test_set.to_csv('../data/output/strat_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce54498-ae7e-41de-b152-642d59dad00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f4ea348-1050-4c3f-945d-1675986876ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31b7576b-96c6-4727-b8a6-a18892039132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/stratified-split.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/stratified-split.py\n",
    "\n",
    "# !pip install sagemaker\n",
    "# %conda install tensorflow\n",
    "# %pip install -U opencv-python-headless\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import (\n",
    "        content_types,\n",
    "        encoders,\n",
    "        env,\n",
    "        modules,\n",
    "        transformer,\n",
    "        worker,\n",
    "        server,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # role = sagemaker.get_execution_role()\n",
    "    region = boto3.Session().region_name\n",
    "\n",
    "    data_bucket = \"dynamodbpetfinder\"\n",
    "    object_prefix = \"interaction_\"\n",
    "    local_path = \"data/interaction/\"\n",
    "\n",
    "    if not os.path.exists(local_path):\n",
    "        os.makedirs(local_path)\n",
    "    else:\n",
    "        shutil.rmtree(local_path)\n",
    "        os.makedirs(local_path)\n",
    "\n",
    "    pattern = r'[0-9]+'\n",
    "    s3 = boto3.client(\"s3\")\n",
    "\n",
    "    result = s3.list_objects(Bucket=data_bucket, Prefix=object_prefix, Delimiter=\"/\")\n",
    "    subfolders = [re.search(pattern, o.get(\"Prefix\")).group() for o in result.get(\"CommonPrefixes\")]\n",
    "    subfolders.sort(reverse=True)\n",
    "\n",
    "    object_path = object_prefix + subfolders[0] + \"/\"\n",
    "    files = s3.list_objects(Bucket=data_bucket, Prefix=object_path, Delimiter=\"/\")\n",
    "\n",
    "    pattern = rf'{object_path}(.+)'\n",
    "    for content in files.get(\"Contents\"):\n",
    "        file_path = content.get(\"Key\")\n",
    "        filename = re.findall(pattern, file_path)[0]\n",
    "        print(filename)\n",
    "\n",
    "        with open(local_path+filename, 'wb') as file:\n",
    "            s3.download_fileobj(\n",
    "                Bucket=data_bucket,\n",
    "                Key=file_path,\n",
    "                Fileobj=file\n",
    "            )\n",
    " \n",
    "    file_list = glob.glob(local_path + \"*\")\n",
    "\n",
    "    print(file_list)\n",
    "\n",
    "    dfs = [] # an empty list to store the data frames\n",
    "    for file in file_list:\n",
    "        data = pd.read_csv(file) # read data frame from csv file\n",
    "        dfs.append(data) # append the data frame to the list\n",
    "\n",
    "    interactions = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "      # rename headers\n",
    "    cl_interactions = interactions.rename(columns={\n",
    "                                  'createdAt': 'created_at',\n",
    "                                  'updatedAt': 'updated_at',\n",
    "                                  })\n",
    "\n",
    "    # convert types\n",
    "    cl_interactions = cl_interactions.astype({\n",
    "                              'like': 'int',\n",
    "                              'click': 'int',\n",
    "                              })\n",
    "    cl_interactions['created_at'] = pd.to_datetime(cl_interactions['created_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    cl_interactions['updated_at'] = pd.to_datetime(cl_interactions['updated_at']).dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    # drop glue columns\n",
    "    cl_interactions = cl_interactions.drop(['__typename', '_lastChangedAt', '_version'], axis=1)\n",
    "\n",
    "    # exporting processed data as csv to local folder\n",
    "\n",
    "    processed_folder = \"processed/auxiliary/\"\n",
    "\n",
    "    if not os.path.exists(processed_folder):\n",
    "        os.makedirs(processed_folder)\n",
    "\n",
    "    cl_interactions.to_csv(f'{processed_folder}interactions.csv')\n",
    "\n",
    "\n",
    "    ## train-test split \n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    test_size = 0.2\n",
    "    validation_size = 0.5 # of test size\n",
    "    random_state = 2023\n",
    "\n",
    "    ## leave some users out\n",
    "\n",
    "    users = cl_interactions['userID'].unique()\n",
    "\n",
    "    train_users, test_users = train_test_split(users, test_size=test_size, shuffle=True, random_state=random_state)\n",
    "    validation_users, test_users = train_test_split(test_users, test_size=validation_size, shuffle=True, random_state=random_state)\n",
    "\n",
    "    train_set = cl_interactions[cl_interactions['userID'].isin(train_users)]\n",
    "    validation_set = cl_interactions[cl_interactions['userID'].isin(validation_users)]\n",
    "    test_set = cl_interactions[cl_interactions['userID'].isin(test_users)]\n",
    "\n",
    "    output_dir = os.path.join(os.getcwd(), \"data/output\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    train_set.to_csv('../data/output/lsuo_train.csv')\n",
    "    validation_set.to_csv('../data/output/lsuo_validation.csv')\n",
    "    test_set.to_csv('../data/output/lsuo_test.csv')\n",
    "\n",
    "    ## stratified split\n",
    "\n",
    "    train_set = cl_interactions.groupby('userID').sample(frac=1-test_size, random_state=random_state)\n",
    "    test_set = cl_interactions.drop(train_set.index)\n",
    "\n",
    "    validation_set = test_set.groupby('userID').sample(frac=validation_size, random_state=random_state)\n",
    "    test_set = test_set.drop(validation_set.index)\n",
    "\n",
    "    print(f'Total number of users: {cl_interactions[\"userID\"].nunique()}')\n",
    "    print(f'Number of users in training: {train_set[\"userID\"].nunique()}')\n",
    "    print(f'Number of users in validation: {validation_set[\"userID\"].nunique()}')\n",
    "    print(f'Number of users in test: {test_set[\"userID\"].nunique()}')\n",
    "\n",
    "    train_set.to_csv('../data/output/strat_train.csv')\n",
    "    validation_set.to_csv('../data/output/strat_validation.csv')\n",
    "    test_set.to_csv('../data/output/strat_test.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d478bfb-22c1-4e34-b575-0581ff7321ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f0cb9d8-ee72-4b3a-85ff-f2d8c2ba0674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name strat-2023-06-14-09-16-24-757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................\u001b[34mrun-1686726857238-part-r-00000\u001b[0m\n",
      "\u001b[34mrun-1686726857238-part-r-00001\u001b[0m\n",
      "\u001b[34mrun-1686726857238-part-r-00002\u001b[0m\n",
      "\u001b[34mrun-1686726857238-part-r-00003\u001b[0m\n",
      "\u001b[34m['data/interaction/run-1686726857238-part-r-00000', 'data/interaction/run-1686726857238-part-r-00003', 'data/interaction/run-1686726857238-part-r-00002', 'data/interaction/run-1686726857238-part-r-00001']\u001b[0m\n",
      "\u001b[34mTotal number of users: 104\u001b[0m\n",
      "\u001b[34mNumber of users in training: 104\u001b[0m\n",
      "\u001b[34mNumber of users in validation: 96\u001b[0m\n",
      "\u001b[34mNumber of users in test: 100\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "bucket_name = \"petfinder6000-training\"\n",
    "base_job_name = \"strat\"\n",
    "\n",
    "sklearn_framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=sklearn_framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=base_job_name,\n",
    "    role=role,\n",
    "    sagemaker_session=Session(default_bucket=bucket_name),\n",
    ")\n",
    "\n",
    "processed_folder = \"./processed/auxiliary/\"\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    code=\"code/stratified-split.py\",\n",
    "    # arguments = [\"arg1\", \"arg2\"], # Arguments can optionally be specified here\n",
    "    inputs=[],\n",
    "    outputs=[\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/train\", output_name=\"train\"),\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/validation\", output_name=\"validation\"),\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/test\", output_name=\"test\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f9ff634-34f0-4064-a6cb-ad5b0ce40021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    processor=sklearn_processor,  # Provide the processor object here\n",
    "    code=\"code/stratified-split.py\",  # Specify the code to be run\n",
    "    inputs=[],  # Provide your inputs\n",
    "    outputs=[  # Specify your outputs\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/train\", output_name=\"train\"),\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/validation\", output_name=\"validation\"),\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/test\", output_name=\"test\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53977406-32fc-4503-a06e-f83a424965e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interactions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-31f2733f69b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'interactions' is not defined"
     ]
    }
   ],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad42c8-1078-4c03-89d4-6f1e565bd182",
   "metadata": {},
   "source": [
    "## Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41a0635a-b733-4be9-995f-ab8066bc9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1654f7c2-3756-4798-9fed-d50f9d40c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "boto_session = boto3.Session(region_name=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e4a7d1c-9d59-40d4-8c54-204934377d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline bucket: s3://petfinder6000-auxiliary/sagemaker-featurestore\n"
     ]
    }
   ],
   "source": [
    "bucket = \"petfinder6000-auxiliary\"\n",
    "prefix = \"sagemaker-featurestore\"\n",
    "offline_feature_store_bucket = 's3://{}/{}'.format(bucket, prefix)\n",
    "print(f'Offline bucket: {offline_feature_store_bucket}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cac2a4e6-e4a1-45ab-b6d0-b77cd202f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name=region)\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region)\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "064dfbee-b87d-4aa6-b99a-9c4286ade491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Create Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0aa47c43-c6b8-4130-876c-7d9a9fc3c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE!!\n",
    "data_type = 'auxiliary'\n",
    "data_name = 'cat-images'\n",
    "file_type = 'pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "edfa6116-fc31-4318-888f-4d94530239b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_name = f'{data_name}-feature-group'\n",
    "feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=feature_store_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aaff9e12-4d36-47bc-ae47-e4438b05f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "processed_dir = 'processed'\n",
    "if file_type == 'csv':\n",
    "    data = pd.read_csv(f'{processed_dir}/{data_type}/{data_name}.{file_type}', header=0)\n",
    "else:\n",
    "    data = pd.read_pickle(f'{processed_dir}/{data_type}/{data_name}.{file_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f7a2fee-e3f6-411c-8179-d9bef2e28973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   index            404 non-null    int64 \n",
      " 1   cws_id           404 non-null    string\n",
      " 2   updated_at       404 non-null    string\n",
      " 3   img_shape        404 non-null    string\n",
      " 4   img_vector       404 non-null    string\n",
      " 5   feature_vectors  404 non-null    string\n",
      "dtypes: int64(1), string(5)\n",
      "memory usage: 19.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d11c85e7-a366-4030-8050-d923fb6c9149",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateFeatureGroup operation: Validation Error: RecordIdentifierFeatureName is not found in names of FeatureDefinitions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-ed5b60141481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevent_time_feature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_time_feature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrole_arn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0menable_online_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/feature_store/feature_group.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, s3_uri, record_identifier_name, event_time_feature_name, role_arn, online_store_kms_key_id, enable_online_store, offline_store_kms_key_id, disable_glue_table_creation, data_catalog_config, description, tags, table_format)\u001b[0m\n\u001b[1;32m    614\u001b[0m             )\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcreate_feature_store_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_feature_group\u001b[0;34m(self, feature_group_name, record_identifier_name, event_time_feature_name, feature_definitions, role_arn, online_store_config, offline_store_config, description, tags)\u001b[0m\n\u001b[1;32m   4909\u001b[0m             \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4910\u001b[0m         )\n\u001b[0;32m-> 4911\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feature_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4913\u001b[0m     def describe_feature_group(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateFeatureGroup operation: Validation Error: RecordIdentifierFeatureName is not found in names of FeatureDefinitions."
     ]
    }
   ],
   "source": [
    "record_identifier_name = \"id\"\n",
    "event_time_feature_name = \"updated_at\"\n",
    "feature_group.load_feature_definitions(data_frame=data)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri=offline_feature_store_bucket,\n",
    "    record_identifier_name=record_identifier_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71185259-7f81-4792-821c-fd0446ae2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check status of feature group creation\n",
    "status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "print(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6f9fd-8a01-42cb-af7d-8820037572ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into feature group\n",
    "feature_group.ingest(data_frame=data, max_workers=3, wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07689d0-e169-4441-a241-16249d41b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client.list_feature_groups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd3494-315c-44dc-9761-9197e435f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to remove feature groups\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# feature_group_name = \"cats-feature-group\"\n",
    "# feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "# feature_group.delete() \n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
