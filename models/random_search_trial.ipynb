{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n"
     ]
    }
   ],
   "source": [
    "import cornac\n",
    "from cornac.data import Reader\n",
    "from cornac.datasets import citeulike\n",
    "from cornac.eval_methods import RatioSplit, BaseMethod\n",
    "from cornac.data import TextModality\n",
    "from cornac.data.text import BaseTokenizer\n",
    "import pandas as pd\n",
    "from cornac.hyperopt import Discrete, Continuous\n",
    "from cornac.hyperopt import GridSearch, RandomSearch\n",
    "\n",
    "from harmonic_mean import HarmonicMean\n",
    "from serendipity_wrapper import Serendipity\n",
    "from combined_eval_method import CombinedBaseMethod\n",
    "from new_random_search import NewRandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_tuplelist(df):\n",
    "\n",
    "    # transform into tuples\n",
    "    tuple_list = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "    # rearrange\n",
    "    for i in range(len(tuple_list)):\n",
    "        tuple_list[i] = (str(tuple_list[i][1]), str(tuple_list[i][0]), float(tuple_list[i][2]))\n",
    "\n",
    "    return tuple_list\n",
    "\n",
    "def df_to_tuplelist_pair(df):\n",
    "    # make into tuples\n",
    "    cats_data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "    # unzip the tuple into 2 lists\n",
    "    cat_ids, texts = zip(*cats_data)\n",
    "\n",
    "    cat_ids = (list(cat_ids))\n",
    "    texts = list(texts)\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = texts[i].replace('\\n', ' ')\n",
    "\n",
    "    return cat_ids, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "STRAT_OR_LSUO = 'strat'\n",
    "\n",
    "data_dir = '../data/output'\n",
    "train_df = pd.read_csv(f'{data_dir}/{STRAT_OR_LSUO}_train.csv', usecols=['catID', 'userID', 'like'])\n",
    "validation_df = pd.read_csv(f'{data_dir}/{STRAT_OR_LSUO}_validation.csv', usecols=['catID', 'userID', 'like'])\n",
    "test_df = pd.read_csv(f'{data_dir}/{STRAT_OR_LSUO}_test.csv', usecols=['catID', 'userID', 'like'])\n",
    "\n",
    "like_data_train = df_to_tuplelist(train_df)\n",
    "like_data_validation = df_to_tuplelist(validation_df)\n",
    "like_data_test = df_to_tuplelist(test_df)\n",
    "\n",
    "\n",
    "DESC_OR_DET = 'details'\n",
    "\n",
    "aux_dir = '../data/auxiliary'\n",
    "cats_df = pd.read_csv(f'{aux_dir}/cats.csv', usecols=['id', DESC_OR_DET])\n",
    "\n",
    "\n",
    "cat_ids, texts = df_to_tuplelist_pair(cats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#junyi's modifications\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# train test val filenames\n",
    "trainfile = 'strat_train'\n",
    "testfile = 'strat_test'\n",
    "valfile = 'strat_validation'\n",
    "\n",
    "# train test val datasets\n",
    "train = pd.read_csv(f'{data_dir}/'+trainfile+'.csv')\n",
    "test = pd.read_csv(f'{data_dir}/'+testfile+'.csv')\n",
    "val = pd.read_csv(f'{data_dir}/'+valfile+'.csv')\n",
    "\n",
    "# main data dataset\n",
    "user = pd.read_csv(f'{aux_dir}/users.csv')\n",
    "cat = pd.read_csv(f'{aux_dir}/cats.csv')\n",
    "# interaction = pd.read_csv('model_data/auxiliary/interaction.csv')\n",
    "\n",
    "# list of datasets\n",
    "dfs = [train, test, val]\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    \n",
    "    # for all\n",
    "    dfs[i]['like'] = dfs[i]['like'].apply(lambda x: 1 if x else 0)\n",
    "    \n",
    "    # train\n",
    "    if i == 0:\n",
    "        dfs[i]['click'] = dfs[i]['click'].apply(lambda x: 1 if x else 0)\n",
    "        dfs[i].drop(['Unnamed: 0', 'id','created_at', 'updated_at'], axis=1, inplace=True)\n",
    "        dfs[i] = dfs[i][['userID', 'catID', 'like', 'dwell_time_ms', 'click']]\n",
    "    \n",
    "    elif i == 1 or i == 2:\n",
    "        dfs[i].drop(['Unnamed: 0', 'id', 'dwell_time_ms', 'click', 'created_at', 'updated_at'], axis=1, inplace=True)\n",
    "        dfs[i] = dfs[i][['userID', 'catID', 'like']]\n",
    "        \n",
    "train, test, val = dfs[0], dfs[1], dfs[2]\n",
    "\n",
    "# checking dwell_time_ms in seconds\n",
    "train['dwell_time_ms'].apply(lambda x: x/1000).describe()\n",
    "\n",
    "# applying log transformation on dwell time to reduce impact of outliers\n",
    "train['dwell_time_ms'].apply(lambda x: np.log(x)).describe()\n",
    "\n",
    "train['log_dwell_time'] = train['dwell_time_ms'].apply(lambda x: np.log(x))\n",
    "train.drop(['dwell_time_ms'], axis=1, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train['norm_log_dwell_time'] = scaler.fit_transform(train[['log_dwell_time']])\n",
    "train.drop(['log_dwell_time'], axis=1, inplace=True)\n",
    "train.head()\n",
    "\n",
    "train_weighted = train.copy()\n",
    "\n",
    "# weights L, C, D for like, click, dwell_time\n",
    "L = 0.5\n",
    "C = 0.25\n",
    "D = 0.25\n",
    "\n",
    "train_weighted['rating'] = L*train_weighted['like'] + C*train_weighted['click'] + D* train_weighted['norm_log_dwell_time']\n",
    "\n",
    "train_weighted.drop(['like','click','norm_log_dwell_time'], axis=1, inplace=True)\n",
    "\n",
    "# convert to tuple\n",
    "like_data_train = [tuple(train_weighted.iloc[i]) for i in range(len(train_weighted))]\n",
    "like_data_test = [tuple(test.iloc[i]) for i in range(len(test))]\n",
    "like_data_validation = [tuple(val.iloc[i]) for i in range(len(val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate a TextModality, it makes it convenient to work with text auxiliary information\n",
    "# For more details, please refer to the tutorial on how to work with auxiliary data\n",
    "item_text_modality = TextModality(\n",
    "    corpus=texts,\n",
    "    ids=cat_ids,\n",
    "    tokenizer=BaseTokenizer(sep=\" \", stop_words=\"english\"),\n",
    "    max_vocab=8000,\n",
    "    max_doc_freq=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = False\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.4\n",
      "---\n",
      "Test data:\n",
      "Number of users = 96\n",
      "Number of items = 187\n",
      "Number of ratings = 479\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 3\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 100\n",
      "Number of items = 196\n",
      "Number of ratings = 488\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 403\n"
     ]
    }
   ],
   "source": [
    "# Define an evaluation method to split feedback into train and test sets\n",
    "bm = CombinedBaseMethod.from_splits(\n",
    "train_data=like_data_train,\n",
    "test_data=like_data_validation,\n",
    "val_data=like_data_test,\n",
    "verbose=True,\n",
    "item_text=item_text_modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CTR model\n",
    "ctr = cornac.models.CTR(name='CTR_desc_strat_false_junyi_harm', k=250, max_iter=200, lambda_v=1)\n",
    "\n",
    "# Use these for evaluation\n",
    "eval_metrics = [\n",
    "    HarmonicMean(\n",
    "        10,\n",
    "        Serendipity(),\n",
    "        cornac.metrics.FMeasure(k=10),\n",
    "        cornac.metrics.NCRR(),\n",
    "        cornac.metrics.NDCG()\n",
    "    ),\n",
    "    Serendipity(),\n",
    "    cornac.metrics.FMeasure(k=10),\n",
    "    cornac.metrics.NCRR(),\n",
    "    cornac.metrics.NDCG()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap MF model inside RandomSearch along with the searching space, try 30 times\n",
    "rs_ctr = NewRandomSearch(\n",
    "    model=ctr,\n",
    "    space=[\n",
    "        Discrete(\"k\", [50, 75, 100, 150, 200]),\n",
    "        Continuous(\"lambda_u\", low=1e-4, high=1e1),\n",
    "        Continuous(\"lambda_v\", low=1e-4, high=1e1),\n",
    "        Continuous(\"a\", low=0.9, high=1),\n",
    "        Continuous(\"b\", low=0.0, high=0.1),\n",
    "        Continuous(\"eta\", low=0.001, high=0.1),\n",
    "    ],\n",
    "    metric=HarmonicMean(\n",
    "        10,\n",
    "        Serendipity(),\n",
    "        cornac.metrics.FMeasure(k=10),\n",
    "        cornac.metrics.NCRR(),\n",
    "        cornac.metrics.NDCG()\n",
    "    ),\n",
    "    eval_method=bm,\n",
    "    n_trails=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RandomSearch_CTR_desc_strat_false_junyi_harm] Training started!\n",
      "Evaluating: {'a': 0.904267111376383, 'b': 0.017835842630054898, 'eta': 0.09644248035592416, 'k': 75, 'lambda_u': 2.7644190625800724, 'lambda_v': 4.401998659388394}\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87ae9feaa833436abfa6dd4c566b647b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning completed!\n",
      "Evaluating: {'a': 0.9072238975088809, 'b': 0.005138303213076967, 'eta': 0.019056349984648762, 'k': 200, 'lambda_u': 1.97920711074904, 'lambda_v': 6.828814638427304}\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6f0a1800db04ba1808b6bdfdb0940ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Put everything together into an experiment and run it\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mcornac\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExperiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mrs_ctr\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_based\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cornac39\\lib\\site-packages\\cornac\\experiment\\experiment.py:131\u001B[0m, in \u001B[0;36mExperiment.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_result()\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels:\n\u001B[1;32m--> 131\u001B[0m     test_result, val_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_method\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_based\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_based\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_validation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow_validation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult\u001B[38;5;241m.\u001B[39mappend(test_result)\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\MITB\\SEM 3 Apr 23\\CS608 Recommender Systems\\Project\\recommender\\models\\combined_eval_method.py:187\u001B[0m, in \u001B[0;36mCombinedBaseMethod.evaluate\u001B[1;34m(self, model, metrics, user_based, show_validation)\u001B[0m\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m] Training started!\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(model\u001B[38;5;241m.\u001B[39mname))\n\u001B[0;32m    186\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 187\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mval_set\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m train_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m##############\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;66;03m# EVALUATION #\u001B[39;00m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;66;03m##############\u001B[39;00m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\MITB\\SEM 3 Apr 23\\CS608 Recommender Systems\\Project\\recommender\\models\\new_base_search.py:29\u001B[0m, in \u001B[0;36mNewBaseSearch.fit\u001B[1;34m(self, train_set, val_set)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(params))\n\u001B[1;32m---> 29\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric, RatingMetric):\n\u001B[0;32m     32\u001B[0m     score \u001B[38;5;241m=\u001B[39m rating_eval(model, [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric], val_set)[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cornac39\\lib\\site-packages\\cornac\\models\\ctr\\recom_ctr.py:138\u001B[0m, in \u001B[0;36mCTR.fit\u001B[1;34m(self, train_set, val_set)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init()\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainable:\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_ctr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cornac39\\lib\\site-packages\\cornac\\models\\ctr\\recom_ctr.py:180\u001B[0m, in \u001B[0;36mCTR._fit_ctr\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    178\u001B[0m loop \u001B[38;5;241m=\u001B[39m trange(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter, disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m loop:\n\u001B[1;32m--> 180\u001B[0m     cf_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_cf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mitem_data\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# u and v updating\u001B[39;00m\n\u001B[0;32m    183\u001B[0m     lda_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mupdate_theta(doc_ids\u001B[38;5;241m=\u001B[39mdoc_ids, doc_cnt\u001B[38;5;241m=\u001B[39mdoc_cnt)\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mupdate_beta()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cornac39\\lib\\site-packages\\cornac\\models\\ctr\\ctr.py:157\u001B[0m, in \u001B[0;36mModel.update_cf\u001B[1;34m(self, user_data, item_data)\u001B[0m\n\u001B[0;32m    155\u001B[0m cf_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msquare(R_j)\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m    156\u001B[0m cf_loss \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msum((U_j\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mV[j])) \u001B[38;5;241m*\u001B[39m R_j)\n\u001B[1;32m--> 157\u001B[0m cf_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mV\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mUU_j\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mV[j])\n\u001B[0;32m    159\u001B[0m ep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mV[j, :] \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtheta[j, :]\n\u001B[0;32m    160\u001B[0m cf_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlambda_v \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msum(ep \u001B[38;5;241m*\u001B[39m ep)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Put everything together into an experiment and run it\n",
    "cornac.Experiment(eval_method=bm, models=[rs_ctr], metrics=eval_metrics, user_based=False).run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdaac5ebe25336d658f1d0203fcb612740709b4e6655fc19b8a7cf1871892904"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('cornac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
