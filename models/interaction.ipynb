{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db7189f",
   "metadata": {},
   "source": [
    "# 1. Import and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1505539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import cornac\n",
    "from cornac.utils import cache\n",
    "from cornac.metrics import NCRR, NDCG, FMeasure\n",
    "from cornac.eval_methods import BaseMethod\n",
    "from cornac.models import MostPop, BPR, WMF, VAECF, SVD\n",
    "from cornac.hyperopt import Discrete, Continuous, RandomSearch\n",
    "\n",
    "from recommenders.evaluation.python_evaluation import serendipity, distributional_coverage, catalog_coverage\n",
    "\n",
    "from harmonic_mean import HarmonicMean\n",
    "from serendipity_wrapper import Serendipity\n",
    "from combined_eval_method import CombinedBaseMethod\n",
    "from new_random_search import NewRandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c3bbb",
   "metadata": {},
   "source": [
    "# 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4373d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to preprocess without combinine features in train set\n",
    "def preprocess(dfs):\n",
    "    for i in range(len(dfs)):\n",
    "\n",
    "        dfs[i].drop(['Unnamed: 0', 'id', 'dwell_time_ms', 'click', 'created_at', 'updated_at'], axis=1, inplace=True)\n",
    "        dfs[i] = dfs[i][['userID', 'catID', 'like']]\n",
    "    \n",
    "    # reassigning train, test, val\n",
    "    train, test, val = dfs[0], dfs[1], dfs[2]\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a38d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to preprocess and combine features in train set\n",
    "def combine_features(dfs_list, like_weight, click_weight, dwell_weight):\n",
    "    \n",
    "    # dfs list in [train, test, val] format\n",
    "    \n",
    "    dfs = dfs_list\n",
    "    L = like_weight\n",
    "    C = click_weight\n",
    "    D = dwell_weight\n",
    "    \n",
    "    for i in range(len(dfs)):\n",
    "    \n",
    "        # convert True/False to 1/0 for all dfs\n",
    "        dfs[i]['like'] = dfs[i]['like'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "\n",
    "        # for train set\n",
    "        if i == 0:\n",
    "            dfs[i]['click'] = dfs[i]['click'].apply(lambda x: 1 if x else 0)\n",
    "            dfs[i].drop(['Unnamed: 0', 'id','created_at', 'updated_at'], axis=1, inplace=True)\n",
    "            dfs[i] = dfs[i][['userID', 'catID', 'like', 'dwell_time_ms', 'click']]\n",
    "\n",
    "\n",
    "        # for test and val sets\n",
    "        elif i == 1 or i == 2:\n",
    "            dfs[i].drop(['Unnamed: 0', 'id', 'dwell_time_ms', 'click', 'created_at', 'updated_at'], axis=1, inplace=True)\n",
    "            dfs[i] = dfs[i][['userID', 'catID', 'like']]\n",
    "    \n",
    "    # reassigning train, test, val\n",
    "    train, test, val = dfs[0], dfs[1], dfs[2]\n",
    "    \n",
    "    # log transform dwell_time\n",
    "    train['log_dwell_time'] = train['dwell_time_ms'].apply(lambda x: np.log(x))\n",
    "    train.drop(['dwell_time_ms'], axis=1, inplace=True)\n",
    "    \n",
    "    # initialize MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # normalizing log_dwell_time\n",
    "    train['norm_log_dwell_time'] = scaler.fit_transform(train[['log_dwell_time']])\n",
    "    train.drop(['log_dwell_time'], axis=1, inplace=True)\n",
    "    \n",
    "    # assigning weights to features\n",
    "    train_weighted = train.copy()\n",
    "    train_weighted['rating'] = L*train_weighted['like'] + C*train_weighted['click'] + D* train_weighted['norm_log_dwell_time']\n",
    "    train_weighted.drop(['like','click','norm_log_dwell_time'], axis=1, inplace=True)\n",
    "    \n",
    "    return train_weighted, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfdb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to form data tuples\n",
    "def form_tuples(df):\n",
    "    return [tuple(df.iloc[i]) for i in range(len(df))]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f945c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate output\n",
    "def make_recommendations(MODEL, TRAINING_SET):\n",
    "    item_id2idx = MODEL.train_set.iid_map\n",
    "    item_idx2id = list(MODEL.train_set.item_ids)\n",
    "    user_idx2id = MODEL.train_set.uid_map\n",
    "    user_idx2id = list(MODEL.train_set.user_ids)\n",
    "   \n",
    "    num_users = len(np.unique(user_idx2id))\n",
    "    \n",
    "    # For each user, get the list of items that they have rated in train and probe\n",
    "    rated = TRAINING_SET.groupby('userID')['catID'].agg(lambda x: list(x))\n",
    "    rated = rated.to_dict()\n",
    "\n",
    "    rec_result = {}\n",
    "\n",
    "    for UIDX in range(0, num_users):\n",
    "        recommendations, scores = MODEL.rank(UIDX)\n",
    "        rec_result[user_idx2id[UIDX]] = [item_idx2id[i] for i in recommendations]\n",
    "\n",
    "    # sort results\n",
    "    rec_result = {key:value for key, value in sorted(rec_result.items(), key=lambda item: item[0])}\n",
    "\n",
    "    # remove the rated items from rec_results\n",
    "    for user in rec_result:\n",
    "        tmp = [x for x in rec_result[user] if x not in rated[user]]\n",
    "        rec_result[user] = tmp\n",
    "\n",
    "    return rated, rec_result\n",
    "\n",
    "# helper function for generating serendipity, distributional coverage and harmonic mean scores\n",
    "def evaluate(EXPERIMENT, TRAINING_SET):\n",
    "    \n",
    "    MODEL = EXPERIMENT.models[0]\n",
    "    \n",
    "    # Get disctionary of rated and recommended items\n",
    "    rated, recommendations = make_recommendations(MODEL, TRAINING_SET)\n",
    "\n",
    "\n",
    "    ### PREPARING DATAFRAMES ###\n",
    "    # Make recommended items into a dataframe for MS recommenders\n",
    "    data = []\n",
    "    \n",
    "    # Iterate over the dictionary keys and values\n",
    "    for key, values in recommendations.items():\n",
    "        # Iterate over the values and append rows to the data list\n",
    "        for value in values:\n",
    "            data.append([key, value])\n",
    "    \n",
    "    # Create the DataFrame with the specified columns\n",
    "    recommendations_df = pd.DataFrame(data, columns=['userID', 'itemID'])\n",
    "\n",
    "    # Make the testing set into a dataframe for MS recommenders\n",
    "    train_df = TRAINING_SET[['userID','catID']].reset_index()\n",
    "    train_df = train_df[['userID','catID']]\n",
    "    train_df = train_df.rename(columns={'userID':'userID', 'catID':'itemID'})\n",
    "\n",
    "\n",
    "    ### METRICS ###\n",
    "    # Calculate serendipity\n",
    "    serendipity_score = serendipity(train_df, recommendations_df)\n",
    "\n",
    "    # Calculate coverage\n",
    "    dist_coverage_score = distributional_coverage(train_df, recommendations_df)\n",
    "\n",
    "    # Extract \n",
    "    for result in EXPERIMENT.result:\n",
    "        model_name = result.model_name\n",
    "        fone10 = result.metric_avg_results['F1@10']\n",
    "        ncrr = result.metric_avg_results['NCRR@-1']\n",
    "        ndcg = result.metric_avg_results['NDCG@-1']\n",
    "\n",
    "    # Calculate harmonic mean\n",
    "    h_mean = hmean([fone10, ncrr, ndcg, dist_coverage_score, serendipity_score])\n",
    "\n",
    "    print(model_name)\n",
    "    print(f\"F1@10: {fone10:.3f}\")\n",
    "    print(f\"NCRR: {ncrr:.3f}\")\n",
    "    print(f\"NDCG: {ndcg:.3f}\")\n",
    "    print(f\"Distributional coverage: {dist_coverage_score:.3f}\")\n",
    "    print(f\"Serendipity: {serendipity_score:.3f}\")\n",
    "    print(f\"Harmonic mean: {h_mean:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac66459",
   "metadata": {},
   "source": [
    "# 3. Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a62344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model\n",
    "def train_model(model_name, weighted, split):\n",
    "    \n",
    "    # model_name ['WMF', 'BPR', 'VAECF']\n",
    "    # weighted ['Yes', 'No']\n",
    "    \n",
    "    # check if model is available \n",
    "    models = ['MostPop', 'WMF', 'BPR', 'VAECF']\n",
    "\n",
    "    if model_name not in models:\n",
    "        print('Model not in available models.')\n",
    "        return   \n",
    "\n",
    "    # load train test val datasets based on split type\n",
    "    train = pd.read_csv('model_data/'+split+'_train.csv')\n",
    "    test = pd.read_csv('model_data/'+split+'_test.csv')\n",
    "    val = pd.read_csv('model_data/'+split+'_validation.csv')\n",
    "\n",
    "    # main data dataset\n",
    "    user = pd.read_csv('Data/user.csv')\n",
    "    cat = pd.read_csv('Data/cat.csv')\n",
    "    \n",
    "    # list of dfs\n",
    "    dfs = [train, test, val]\n",
    "    \n",
    "    # preprocess based on choice if weighted or not\n",
    "    if weighted == 'Yes':\n",
    "        # weights for like, click, dwell_time: 0.5, 0.25, 0.25\n",
    "        train, test, val = combine_features(dfs, 0.5, 0.25, 0.25)\n",
    "    \n",
    "    elif weighted == 'No':\n",
    "        train, test, val = preprocess(dfs)\n",
    "    \n",
    "    else:\n",
    "        print(\"Enter 'Yes' or 'No' for weighted ratings\")\n",
    "        return   \n",
    "        \n",
    "    # forming data tuples\n",
    "    train_data = form_tuples(train)\n",
    "    val_data = form_tuples(val)\n",
    "    test_data = form_tuples(test)\n",
    "\n",
    "    \n",
    "    # define base method\n",
    "    base_method = CombinedBaseMethod.from_splits(\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        test_data=test_data,\n",
    "        verbose=True,\n",
    "        exclude_unknowns=True,\n",
    "        )\n",
    "        \n",
    "    # define evaluation metrics\n",
    "    eval_metrics = [\n",
    "        HarmonicMean(\n",
    "            10,\n",
    "            Serendipity(),\n",
    "            cornac.metrics.FMeasure(k=10),\n",
    "            cornac.metrics.NCRR(),\n",
    "            cornac.metrics.NDCG()\n",
    "        ),\n",
    "        Serendipity(),\n",
    "        cornac.metrics.FMeasure(k=10),\n",
    "        cornac.metrics.NCRR(),\n",
    "        cornac.metrics.NDCG()\n",
    "    ]\n",
    "    \n",
    "    # define verbose and seed\n",
    "    VERBOSE = False\n",
    "    SEED = 2023\n",
    "    \n",
    "    if model_name == 'MostPop':\n",
    "        \n",
    "        rs_model = MostPop() # not rs\n",
    "    \n",
    "    elif model_name == 'WMF':\n",
    "        \n",
    "        # define model\n",
    "        model = WMF(max_iter=200, a=1.0, verbose=VERBOSE, seed=SEED)\n",
    "        \n",
    "        # define parameters to perform RandomSearch on\n",
    "        wmf_params = [\n",
    "        Discrete('k', list(range(5,101))),\n",
    "        Continuous('b', low=0.01, high=0.1),\n",
    "        Continuous('lambda_u', low=0.01, high=0.1),\n",
    "        Continuous('lambda_v', low=0.01, high=0.1),\n",
    "        Continuous('learning_rate', low=0.001, high=0.01)\n",
    "        ]\n",
    "\n",
    "        rs_model = NewRandomSearch(\n",
    "            model=model,\n",
    "            space=wmf_params,\n",
    "            metric=HarmonicMean(\n",
    "                10,\n",
    "                Serendipity(),\n",
    "                cornac.metrics.FMeasure(k=10),\n",
    "                cornac.metrics.NCRR(),\n",
    "                cornac.metrics.NDCG()\n",
    "            ),\n",
    "            eval_method=base_method,\n",
    "            n_trails=100\n",
    "        )\n",
    "        \n",
    "    elif model_name == 'BPR':\n",
    "        \n",
    "        # define model\n",
    "        model = BPR(max_iter=200, verbose=VERBOSE, seed=SEED)\n",
    "        \n",
    "        # define parameters to perform RandomSearch on\n",
    "        bpr_params = [\n",
    "            Discrete('k', list(range(5,101))),\n",
    "            Continuous('lambda_reg', low=0.01, high=0.1),\n",
    "            Continuous('learning_rate', low=0.001, high=0.01)\n",
    "        ]\n",
    "\n",
    "        \n",
    "        rs_model = NewRandomSearch(\n",
    "            model=model,\n",
    "            space=bpr_params,\n",
    "            metric=HarmonicMean(\n",
    "                10,\n",
    "                Serendipity(),\n",
    "                cornac.metrics.FMeasure(k=10),\n",
    "                cornac.metrics.NCRR(),\n",
    "                cornac.metrics.NDCG()\n",
    "            ),\n",
    "            eval_method=base_method,\n",
    "            n_trails=100\n",
    "        )\n",
    "  \n",
    "    elif model_name == 'VAECF':\n",
    "        \n",
    "        # define model\n",
    "        model = VAECF(autoencoder_structure = [30], act_fn='relu', likelihood='bern', verbose=VERBOSE, seed=SEED)\n",
    "\n",
    "        # define parameters to perform RandomSearch on\n",
    "        vaecf_params = [\n",
    "            Discrete('k', list(range(5,101))),\n",
    "            Discrete('n_epochs', list(range(5,51))),\n",
    "            Discrete('batch_size', [8, 16, 32, 64]),\n",
    "            Continuous('learning_rate', low=0.001, high=0.01)\n",
    "        ]\n",
    "\n",
    "        rs_model = NewRandomSearch(\n",
    "            model=model,\n",
    "            space=vaecf_params,\n",
    "            metric=HarmonicMean(\n",
    "                10,\n",
    "                Serendipity(),\n",
    "                cornac.metrics.FMeasure(k=10),\n",
    "                cornac.metrics.NCRR(),\n",
    "                cornac.metrics.NDCG()\n",
    "            ),\n",
    "            eval_method=base_method,\n",
    "            n_trails=100\n",
    "        )\n",
    "        \n",
    "    # run experiment\n",
    "    experiment = cornac.Experiment(eval_method=base_method, models=[rs_model], metrics=eval_metrics)\n",
    "    experiment.run()\n",
    "    \n",
    "    if model_name != 'MostPop':\n",
    "\n",
    "        # print best params\n",
    "        print('Random search best params: ', rs_model.best_params)\n",
    "\n",
    "    EXPERIMENT = experiment\n",
    "\n",
    "    # training set in dataframe\n",
    "    TRAINING_SET = train\n",
    "\n",
    "    # evaluate and calculate harmonic mean\n",
    "    evaluate(EXPERIMENT, TRAINING_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4c309",
   "metadata": {},
   "source": [
    "# 4. Model (likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de533efe",
   "metadata": {},
   "source": [
    "## 4a. MostPop (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5755f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe44692e3c646e692df596ef55c02c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ddf59e7c9d4263a6715a7411f7a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "        |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "------- + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "MostPop | 0.0264 |       0.0070 |  0.0613 |  0.2528 |      0.0091 |   1.8221\n",
      "\n",
      "TEST:\n",
      "...\n",
      "        |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "------- + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "MostPop | 0.0195 |       0.0067 |  0.0509 |  0.2378 |      0.0084 |    0.0000 |   2.1794\n",
      "\n",
      "MostPop\n",
      "F1@10: 0.020\n",
      "NCRR: 0.051\n",
      "NDCG: 0.238\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'MostPop'\n",
    "weighted = 'No'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b291bce4",
   "metadata": {},
   "source": [
    "## 4b. WMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abea2dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[RandomSearch_WMF] Training started!\n",
      "\n",
      "[RandomSearch_WMF] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36a72aa2aef4236bf4c9b1374572ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c187a31e1f4d3ca2531d7a6f0145c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "RandomSearch_WMF | 0.0480 |       0.0110 |  0.0827 |  0.2690 |      0.0091 |   1.7920\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "RandomSearch_WMF | 0.0250 |       0.0090 |  0.0488 |  0.2324 |      0.0084 |  235.7415 |   2.2274\n",
      "\n",
      "Random search best params:  {'b': 0.025261213725309373, 'k': 8, 'lambda_u': 0.07386316292472243, 'lambda_v': 0.02037184386106846, 'learning_rate': 0.007595146617364617}\n",
      "RandomSearch_WMF\n",
      "F1@10: 0.025\n",
      "NCRR: 0.049\n",
      "NDCG: 0.232\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'WMF'\n",
    "weighted = 'No'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d2d07",
   "metadata": {},
   "source": [
    "## 4c. BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcf3da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[RandomSearch_BPR] Training started!\n",
      "\n",
      "[RandomSearch_BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e8e5e53e244769a439bf2843696cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4a5388da2749b2814cece77cf3e812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "RandomSearch_BPR | 0.0341 |       0.0081 |  0.0649 |  0.2570 |      0.0091 |   2.4646\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "RandomSearch_BPR | 0.0237 |       0.0077 |  0.0571 |  0.2434 |      0.0084 |  229.8970 |   2.9866\n",
      "\n",
      "Random search best params:  {'k': 90, 'lambda_reg': 0.02638440948158871, 'learning_rate': 0.0034852161694518707}\n",
      "RandomSearch_BPR\n",
      "F1@10: 0.024\n",
      "NCRR: 0.057\n",
      "NDCG: 0.243\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'BPR'\n",
    "weighted = 'No'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd2195",
   "metadata": {},
   "source": [
    "## 4d. VAECF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91a5646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[RandomSearch_VAECF] Training started!\n",
      "\n",
      "[RandomSearch_VAECF] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d834901c8c94c86a962712e2b71e671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd745d15cc14228957d1fefe6bb1ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "                   |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "------------------ + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "RandomSearch_VAECF | 0.0311 |       0.0104 |  0.0737 |  0.2612 |      0.0091 |   1.8261\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                   |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "------------------ + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "RandomSearch_VAECF | 0.0439 |       0.0097 |  0.0698 |  0.2554 |      0.0084 |  195.3128 |   2.1799\n",
      "\n",
      "Random search best params:  {'batch_size': 32, 'k': 61, 'learning_rate': 0.005950313122404854, 'n_epochs': 10}\n",
      "RandomSearch_VAECF\n",
      "F1@10: 0.044\n",
      "NCRR: 0.070\n",
      "NDCG: 0.255\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'VAECF'\n",
    "weighted = 'No'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60526ba",
   "metadata": {},
   "source": [
    "# 5. Model (weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1aaf85",
   "metadata": {},
   "source": [
    "## 5a. WMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f35ce93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_j\\AppData\\Local\\Temp\\ipykernel_42588\\713831474.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['log_dwell_time'] = train['dwell_time_ms'].apply(lambda x: np.log(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.4\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[RandomSearch_WMF] Training started!\n",
      "\n",
      "[RandomSearch_WMF] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f2355264a94056a1f631a68e3d7010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90ea3b3c466426d9709af2f690ce8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "RandomSearch_WMF | 0.0314 |       0.0097 |  0.0687 |  0.2571 |      0.0091 |   1.8276\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "RandomSearch_WMF | 0.0253 |       0.0094 |  0.0783 |  0.2552 |      0.0084 |  240.0232 |   2.2034\n",
      "\n",
      "Random search best params:  {'b': 0.039183708492442515, 'k': 8, 'lambda_u': 0.02580558032415233, 'lambda_v': 0.09497617610357131, 'learning_rate': 0.005812383052067089}\n",
      "RandomSearch_WMF\n",
      "F1@10: 0.025\n",
      "NCRR: 0.078\n",
      "NDCG: 0.255\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'WMF'\n",
    "weighted = 'Yes'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73f0f7",
   "metadata": {},
   "source": [
    "## 5b. BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a48bc471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_j\\AppData\\Local\\Temp\\ipykernel_42588\\713831474.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['log_dwell_time'] = train['dwell_time_ms'].apply(lambda x: np.log(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.4\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[RandomSearch_BPR] Training started!\n",
      "\n",
      "[RandomSearch_BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011e5620273d4d4cbfcf90590b96c28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f357138051f4a93a3779804fa84a47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "RandomSearch_BPR | 0.0341 |       0.0081 |  0.0649 |  0.2570 |      0.0091 |   2.4711\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                 |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "---------------- + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "RandomSearch_BPR | 0.0237 |       0.0077 |  0.0571 |  0.2434 |      0.0084 |  232.0694 |   2.9961\n",
      "\n",
      "Random search best params:  {'k': 90, 'lambda_reg': 0.02638440948158871, 'learning_rate': 0.0034852161694518707}\n",
      "RandomSearch_BPR\n",
      "F1@10: 0.024\n",
      "NCRR: 0.057\n",
      "NDCG: 0.243\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'BPR'\n",
    "weighted = 'Yes'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fd185f",
   "metadata": {},
   "source": [
    "## 5c. VAECF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eb78093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_j\\AppData\\Local\\Temp\\ipykernel_42588\\713831474.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['log_dwell_time'] = train['dwell_time_ms'].apply(lambda x: np.log(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating from splits\n",
      "initialising Combined Base\n",
      "rating_threshold = 1.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 104\n",
      "Number of items = 400\n",
      "Number of ratings = 3874\n",
      "Max rating = 1.0\n",
      "Min rating = 0.0\n",
      "Global mean = 0.4\n",
      "---\n",
      "Test data:\n",
      "Number of users = 100\n",
      "Number of items = 195\n",
      "Number of ratings = 487\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 96\n",
      "Number of items = 184\n",
      "Number of ratings = 476\n",
      "---\n",
      "Total users = 104\n",
      "Total items = 400\n",
      "\n",
      "[RandomSearch_VAECF] Training started!\n",
      "\n",
      "[RandomSearch_VAECF] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535cae89205e46aead3f1d656c65a208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3260393c1f04d32a37178a9a5110360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALIDATION:\n",
      "...\n",
      "                   |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Time (s)\n",
      "------------------ + ------ + ------------ + ------- + ------- + ----------- + --------\n",
      "RandomSearch_VAECF | 0.0311 |       0.0104 |  0.0737 |  0.2612 |      0.0091 |   1.8546\n",
      "\n",
      "TEST:\n",
      "...\n",
      "                   |  F1@10 | HarmonicMean | NCRR@-1 | NDCG@-1 | Serendipity | Train (s) | Test (s)\n",
      "------------------ + ------ + ------------ + ------- + ------- + ----------- + --------- + --------\n",
      "RandomSearch_VAECF | 0.0439 |       0.0097 |  0.0698 |  0.2554 |      0.0084 |  196.5974 |   2.1824\n",
      "\n",
      "Random search best params:  {'batch_size': 32, 'k': 61, 'learning_rate': 0.005950313122404854, 'n_epochs': 10}\n",
      "RandomSearch_VAECF\n",
      "F1@10: 0.044\n",
      "NCRR: 0.070\n",
      "NDCG: 0.255\n",
      "Distributional coverage: 8.633\n",
      "Serendipity: 0.814\n",
      "Harmonic mean: 0.118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'VAECF'\n",
    "weighted = 'Yes'\n",
    "split = 'strat'\n",
    "train_model(model_name, weighted, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c2c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
